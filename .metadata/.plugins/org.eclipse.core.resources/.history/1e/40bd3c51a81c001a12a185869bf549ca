package com.simen.webCrawler;

import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStreamReader;
import java.net.MalformedURLException;
import java.net.URL;
import java.util.regex.Pattern;

public class Crawler {
	
	/**
	 * @param urlString
	 * @return
	 */
	public static String getHTML(String urlString) {
		StringBuilder sb = new StringBuilder();
		
		try {
			URL url = new URL(urlString);
			
			BufferedReader reader = new BufferedReader(new InputStreamReader(url.openStream()));
			String temp = "";
			while((temp=reader.readLine())!=null) {
				sb.append(temp);
				sb.append("\n");
			}
		} catch (MalformedURLException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
		return sb.toString();
		
	}
	
	public static String[] getURLs(String html) {
		Pattern p = Pattern.compile("[a-zA-z]+://[^\\s]*");
		return null;
	}
	public static void main(String[] args) {
		String html = getHTML("https://www.bbc.com/");
		System.out.println(html);
	}
}
